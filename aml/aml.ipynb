{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c641916-474f-4495-bf56-4605813a8da6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomalies: [[-2.16049888 -0.25828928]\n",
      " [-1.59150602  2.27352377]\n",
      " [ 0.56553802  3.19915935]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "# generate sample data\n",
    "X = np.random.randn(100, 2) # 100 samples with 2 features\n",
    "\n",
    "# fit the Local Outlier Factor model\n",
    "clf = LocalOutlierFactor(n_neighbors=20)\n",
    "y_pred = clf.fit_predict(X)\n",
    "\n",
    "# identify anomalies (outliers)\n",
    "anomalies = X[y_pred==-1]\n",
    "\n",
    "print(\"Anomalies:\", anomalies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd2896d-bfc9-4dbb-97da-7a59d736eea7",
   "metadata": {},
   "source": [
    "In this example, we're using the LocalOutlierFactor algorithm from the sklearn.neighbors module to detect anomalies in a 2D dataset. The n_neighbors parameter specifies the number of neighbors to use for the outlier detection.\n",
    "\n",
    "The fit_predict method of the LocalOutlierFactor model returns a label for each sample, where -1 indicates an outlier and 1 indicates an inlier.\n",
    "\n",
    "Finally, we extract the anomalies (samples with label -1) from the original dataset X and print them to the console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf768cd-0db7-441a-a0bc-60d9d4f0296d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577dc87f-8986-4f97-9c48-97e3ea53c003",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef82a48e-27b9-4524-b050-b066d0e3c761",
   "metadata": {},
   "source": [
    "Anomaly detection is a common machine learning problem that involves identifying patterns in data that are unusual or unexpected. Here is a simple Python code for anomaly detection using the Isolation Forest algorithm from the scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "616f3780-039b-44dc-aa5a-b42c1f745699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "# Generate some example data\n",
    "data = np.random.randn(100, 2)\n",
    "\n",
    "# Initialize the Isolation Forest algorithm\n",
    "clf = IsolationForest(random_state=0)\n",
    "\n",
    "# Fit the model to the data\n",
    "clf.fit(data)\n",
    "\n",
    "# Predict the anomaly score for each point\n",
    "scores = clf.decision_function(data)\n",
    "\n",
    "# Print the scores and corresponding data points\n",
    "for i, score in enumerate(scores):\n",
    "    print(f\"Data point {i}: anomaly score = {score}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bcbda7-84e0-4664-a04c-48465229094a",
   "metadata": {},
   "source": [
    "In this code, we first generate some example data as a 100 x 2 numpy array. We then initialize an instance of the Isolation Forest algorithm with a random seed of 0. Next, we fit the model to the data using the fit method. Finally, we use the decision_function method to predict the anomaly score for each data point, which represents the degree of abnormality of each point relative to the rest of the data. We print out the scores and corresponding data points in a loop to visualize the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31906763-e18e-4d42-b6ba-c3500b72b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "class AnomalyDetector:\n",
    "    def __init__(self, random_state=0):\n",
    "        \"\"\"\n",
    "        Initialize the AnomalyDetector class with a given random state.\n",
    "\n",
    "        Parameters:\n",
    "        random_state (int): Random seed for the Isolation Forest algorithm.\n",
    "        \"\"\"\n",
    "        self.clf = IsolationForest(random_state=random_state)\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        Fit the Isolation Forest model to the given data.\n",
    "\n",
    "        Parameters:\n",
    "        data (np.ndarray): Input data as a numpy array.\n",
    "        \"\"\"\n",
    "        self.clf.fit(data)\n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        Predict the anomaly score for each point in the given data.\n",
    "\n",
    "        Parameters:\n",
    "        data (np.ndarray): Input data as a numpy array.\n",
    "\n",
    "        Returns:\n",
    "        scores (np.ndarray): Anomaly scores for each data point as a numpy array.\n",
    "        \"\"\"\n",
    "        scores = self.clf.decision_function(data)\n",
    "        return scores\n",
    "\n",
    "    def detect(self, data, threshold=0):\n",
    "        \"\"\"\n",
    "        Detect anomalies in the given data based on a threshold.\n",
    "\n",
    "        Parameters:\n",
    "        data (np.ndarray): Input data as a numpy array.\n",
    "        threshold (float): Anomaly score threshold for determining outliers. Defaults to 0.\n",
    "\n",
    "        Returns:\n",
    "        mask (np.ndarray): Boolean mask indicating the presence of anomalies in the data.\n",
    "        \"\"\"\n",
    "        scores = self.predict(data)\n",
    "        mask = scores < threshold\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f7ae7-37d5-43a8-b4fd-cea722408d89",
   "metadata": {},
   "source": [
    "In this advanced class, we have defined an AnomalyDetector class with three methods:\n",
    "\n",
    "__init__: This is the constructor method that initializes the class with a given random state for the Isolation Forest algorithm.\n",
    "\n",
    "fit: This method fits the Isolation Forest model to the input data.\n",
    "\n",
    "predict: This method predicts the anomaly score for each point in the input data.\n",
    "\n",
    "detect: This method detects anomalies in the input data based on a given threshold.\n",
    "\n",
    "The detect method returns a boolean mask indicating the presence of anomalies in the data. This allows the user to easily visualize and interpret the results of the anomaly detection algorithm. The user can also specify a threshold value for the anomaly score to customize the sensitivity of the detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5247a502-2fd0-4307-bb7c-02b9c0688a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "class AntiAnomalyDetector:\n",
    "    def __init__(self, random_state=0):\n",
    "        \"\"\"\n",
    "        Initialize the AntiAnomalyDetector class with a given random state.\n",
    "\n",
    "        Parameters:\n",
    "        random_state (int): Random seed for the Isolation Forest algorithm.\n",
    "        \"\"\"\n",
    "        self.clf = IsolationForest(random_state=random_state)\n",
    "\n",
    "    def fit(self, data):\n",
    "        \"\"\"\n",
    "        Fit the Isolation Forest model to the given data.\n",
    "\n",
    "        Parameters:\n",
    "        data (np.ndarray): Input data as a numpy array.\n",
    "        \"\"\"\n",
    "        self.clf.fit(data)\n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        Predict the normality score for each point in the given data.\n",
    "\n",
    "        Parameters:\n",
    "        data (np.ndarray): Input data as a numpy array.\n",
    "\n",
    "        Returns:\n",
    "        scores (np.ndarray): Normality scores for each data point as a numpy array.\n",
    "        \"\"\"\n",
    "        scores = self.clf.score_samples(data)\n",
    "        return scores\n",
    "\n",
    "    def detect(self, data, threshold=0):\n",
    "        \"\"\"\n",
    "        Detect normal data points in the given data based on a threshold.\n",
    "\n",
    "        Parameters:\n",
    "        data (np.ndarray): Input data as a numpy array.\n",
    "        threshold (float): Normality score threshold for determining normal data points. Defaults to 0.\n",
    "\n",
    "        Returns:\n",
    "        mask (np.ndarray): Boolean mask indicating the presence of normal data points in the data.\n",
    "        \"\"\"\n",
    "        scores = self.predict(data)\n",
    "        mask = scores > threshold\n",
    "        return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5d285d-b827-42d7-b1b4-a6e5dc09c716",
   "metadata": {},
   "source": [
    "In this code, we have defined an AntiAnomalyDetector class with three methods:\n",
    "\n",
    "__init__: This is the constructor method that initializes the class with a given random state for the Isolation Forest algorithm.\n",
    "\n",
    "fit: This method fits the Isolation Forest model to the input data.\n",
    "\n",
    "predict: This method predicts the normality score for each point in the input data.\n",
    "\n",
    "detect: This method detects normal data points in the input data based on a given threshold.\n",
    "\n",
    "The detect method returns a boolean mask indicating the presence of normal data points in the data. This allows the user to easily visualize and interpret the results of the anti-anomaly detection algorithm.\n",
    "The user can also specify a threshold value for the normality score to customize the sensitivity of the detector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0a0ec8-3cb2-4b10-b379-65794e75af88",
   "metadata": {},
   "source": [
    "# AML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c757a19-9917-4b4e-a174-858525dcbbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from datetime import datetime\n",
    "\n",
    "# Read in transaction data\n",
    "df = pd.read_csv('transaction_data.csv')\n",
    "\n",
    "# Convert transaction date to datetime format\n",
    "df['transaction_date'] = pd.to_datetime(df['transaction_date'])\n",
    "\n",
    "# Sort by transaction date\n",
    "df = df.sort_values('transaction_date')\n",
    "\n",
    "# Calculate time since last transaction for each account\n",
    "df['time_since_last_transaction'] = df.groupby('account')['transaction_date'].diff().dt.days\n",
    "\n",
    "# Calculate rolling 7-day transaction volume for each account\n",
    "df['7_day_transaction_volume'] = df.groupby('account')['amount'].rolling('7d').sum().values\n",
    "\n",
    "# Calculate z-score for 7-day transaction volume for each account\n",
    "scaler = StandardScaler()\n",
    "df['7_day_transaction_volume_zscore'] = scaler.fit_transform(df['7_day_transaction_volume'].values.reshape(-1, 1))\n",
    "\n",
    "# Use KMeans clustering to identify transaction clusters\n",
    "kmeans = KMeans(n_clusters=10)\n",
    "df['transaction_cluster'] = kmeans.fit_predict(df[['amount', '7_day_transaction_volume_zscore']])\n",
    "\n",
    "# Use Isolation Forest to detect outliers in transaction clusters\n",
    "outliers_fraction = 0.01\n",
    "model = IsolationForest(contamination=outliers_fraction)\n",
    "df['is_outlier'] = model.fit_predict(df[['amount', '7_day_transaction_volume_zscore']])\n",
    "\n",
    "# Flag suspicious transactions\n",
    "df['is_suspicious'] = np.where((df['time_since_last_transaction'] > 7) &\n",
    "                               (df['7_day_transaction_volume_zscore'] > 3) &\n",
    "                               (df['is_outlier'] == -1), 1, 0)\n",
    "\n",
    "# Export suspicious transactions to a CSV file\n",
    "df[df['is_suspicious'] == 1].to_csv('suspicious_transactions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c7a107-bfe5-4abc-a68d-9b27e95eb532",
   "metadata": {},
   "source": [
    "Anti-Money Laundering (AML) is a complex topic and requires a variety of techniques and technologies to detect and prevent financial crimes. Here is a basic Python code for implementing AML measures:\n",
    "This code reads in transaction data from a CSV file and performs the following AML measures:\n",
    "\n",
    "- Converts the transaction date to a datetime format and sorts the data by date.\n",
    "- Calculates the time since the last transaction for each account.\n",
    "- Calculates the rolling 7-day transaction volume for each account.\n",
    "- Calculates the z-score for the 7-day transaction volume for each account using standard scaling.\n",
    "- Uses KMeans clustering to identify transaction clusters based on amount and 7-day transaction volume.\n",
    "- Uses Isolation Forest to detect outliers in each transaction cluster.\n",
    "- Flags suspicious transactions that meet the following criteria:\n",
    "- Time since last transaction is greater than 7 days.\n",
    "- 7-day transaction volume z-score is greater than 3.\n",
    "- Transaction is identified as an outlier by the Isolation Forest model.\n",
    "\n",
    "Exports suspicious transactions to a CSV file.\n",
    "Note that this code is just a basic implementation and may need to be customized and adjusted for specific AML requirements and regulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba53661b-9b87-4c8c-ab92-ef14d2131ce2",
   "metadata": {},
   "source": [
    "# AML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438a17d8-98cd-4d82-b337-2829c093d18e",
   "metadata": {},
   "source": [
    "As an AI language model, I cannot create a complete Python code for anti-money laundering on my own, as the process requires a thorough understanding of the relevant laws and regulations and access to relevant data. However, I can provide you with an overview of the steps involved in developing an anti-money laundering system and some basic Python code for data processing that can be used as a starting point.\n",
    "\n",
    "Data Collection and Processing:\n",
    "The first step is to collect relevant data from various sources such as financial transactions, customer information, and public records. The data collected needs to be processed to identify suspicious patterns that may indicate money laundering activities. Here is some sample Python code for data processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d24ad8b-6251-4a59-a6cc-7b47bfd6557d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data from a CSV file\n",
    "data = pd.read_csv('transactions.csv')\n",
    "\n",
    "# Filter transactions for suspicious activity\n",
    "suspicious = data[data['amount'] > 10000]\n",
    "\n",
    "# Save suspicious transactions to a new CSV file\n",
    "suspicious.to_csv('suspicious_transactions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701886af-a36f-4149-a8b5-7783ec180437",
   "metadata": {},
   "source": [
    "Risk Assessment:\n",
    "Once the suspicious transactions have been identified, the next step is to assess the risk associated with each transaction. This involves analyzing various factors such as the type of transaction, the parties involved, and the source of funds. Here is some sample Python code for risk assessment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c6fb48e-ddf2-4b15-b1cd-d5f5e3f4d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load suspicious transactions from CSV file\n",
    "suspicious = pd.read_csv('suspicious_transactions.csv')\n",
    "\n",
    "# Calculate risk score for each transaction\n",
    "suspicious['risk_score'] = (suspicious['amount'] / suspicious['balance']) * 100\n",
    "\n",
    "# Save transactions and risk scores to a new CSV file\n",
    "suspicious.to_csv('suspicious_transactions_with_risk_scores.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec02429-2043-4eff-a243-2ecd71ad0dc1",
   "metadata": {},
   "source": [
    "Reporting:\n",
    "The final step is to report suspicious transactions to the relevant authorities as per regulatory requirements. Here is some sample Python code for generating a report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec9d0aa-991f-4e3b-9760-c5e0ddb6d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load suspicious transactions with risk scores from CSV file\n",
    "suspicious = pd.read_csv('suspicious_transactions_with_risk_scores.csv')\n",
    "\n",
    "# Generate report for transactions with high risk scores\n",
    "high_risk = suspicious[suspicious['risk_score'] > 10]\n",
    "report = high_risk[['transaction_id', 'customer_id', 'amount', 'risk_score']]\n",
    "report.to_csv('high_risk_transactions_report.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221d885-6ca7-4fe4-ad83-db68d39eec3f",
   "metadata": {},
   "source": [
    "Please note that the above code is just a basic example and needs to be adapted to the specific needs and requirements of your organization and regulatory environment. It is also important to note that anti-money laundering systems require continuous monitoring and improvement to be effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d981046-343e-4f0f-acfb-144eedd10bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2be5b12-de6c-41d4-9af8-f2cf5f616854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acba5da1-b3d3-450b-b815-9642921ecf92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26144031-3f3f-4909-96ad-39534223b03b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
